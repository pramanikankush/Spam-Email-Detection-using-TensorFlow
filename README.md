ğŸ“§ Spam Email Detection using TensorFlow

A deep learning project to automatically classify emails as Spam or Ham (Not Spam) using TensorFlow and LSTM networks.

This project demonstrates data preprocessing, balancing imbalanced classes, text cleaning, tokenization, and model training with callbacks for optimal performance.

ğŸš€ Features

Preprocessing pipeline for text cleaning (stopwords, punctuation removal).

Class balancing using downsampling.

WordCloud visualization for insights into email text.

Tokenizer & Padding to convert text into numerical sequences.

Deep Learning Model: Embedding + LSTM + Dense Layers.

Training with EarlyStopping & ReduceLROnPlateau.

Achieves high accuracy on email spam classification.

ğŸ“‚ Dataset

The dataset contains 5171 rows and 4 columns of labeled emails.

label: Email type (spam / ham)

text: The email content

Other metadata columns

Download Dataset: Emails.csv
 (Add your dataset link here)

ğŸ› ï¸ Tech Stack

Python 3.x

TensorFlow / Keras

NLTK (Stopwords removal)

Pandas, NumPy, Matplotlib, Seaborn

WordCloud for visualization

Scikit-learn for data splitting

ğŸ“Š Workflow
1ï¸âƒ£ Import Libraries

Load essential libraries for preprocessing, visualization, and deep learning.

2ï¸âƒ£ Load Dataset
data = pd.read_csv('Emails.csv')
print(data.shape)  # (5171, 4)

3ï¸âƒ£ Handle Class Imbalance

Downsample the Ham class to balance with Spam emails.

4ï¸âƒ£ Preprocess Text

Remove Subject

Remove punctuations

Remove stopwords

Convert text to lowercase

5ï¸âƒ£ Visualize Data

Label distribution using Seaborn

Frequent words using WordCloud

6ï¸âƒ£ Tokenization & Padding

Convert emails to sequences of integers and pad them to equal length.

7ï¸âƒ£ Model Architecture
model = tf.keras.models.Sequential([
    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=32, input_length=100),
    tf.keras.layers.LSTM(16),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

8ï¸âƒ£ Training

Use EarlyStopping & ReduceLROnPlateau to optimize learning.

history = model.fit(
    train_sequences, train_Y,
    validation_data=(test_sequences, test_Y),
    epochs=20,
    batch_size=32,
    callbacks=[lr, es]
)

ğŸ“ˆ Model Summary

Embedding Layer â†’ Word vector representation

LSTM Layer â†’ Sequence learning

Dense Layers â†’ Feature extraction

Sigmoid Output Layer â†’ Binary classification (Spam/Ham)

Parameters: ~1.28M trainable

ğŸ“‰ Results

Accuracy: ~90%+ (depending on dataset split & preprocessing)

Balanced performance on Spam & Ham emails

ğŸ”® Future Improvements

Use Bi-directional LSTM/GRU for better sequence capture

Try pre-trained embeddings (GloVe, Word2Vec)

Experiment with transformer-based models (BERT, DistilBERT)

Deploy model as a Flask/Streamlit Web App

â–¶ï¸ How to Run

Clone the repo

git clone https://github.com/yourusername/spam-email-detection.git
cd spam-email-detection


Install requirements

pip install -r requirements.txt


Run the script

python spam_detector.py


Train the model & check results

ğŸ“Œ Requirements

requirements.txt should include:

numpy
pandas
matplotlib
seaborn
nltk
wordcloud
scikit-learn
tensorflow
keras

ğŸ™Œ Contribution

Pull requests are welcome! For major changes, open an issue first to discuss what youâ€™d like to add.

ğŸ“œ License

This project is licensed under the MIT License.
